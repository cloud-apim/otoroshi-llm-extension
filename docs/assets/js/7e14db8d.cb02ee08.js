"use strict";(self.webpackChunkdocumentation=self.webpackChunkdocumentation||[]).push([[4094],{8675:(n,e,t)=>{t.r(e),t.d(e,{assets:()=>l,contentTitle:()=>a,default:()=>u,frontMatter:()=>i,metadata:()=>r,toc:()=>c});var o=t(4848),s=t(8453);t(9229);const i={sidebar_position:2},a="\ud83d\udcb2 Costs tracking",r={id:"cost-optimizations/costs-tracking",title:"\ud83d\udcb2 Costs tracking",description:"If you want to track the costs of your LLM Usage, you can enable it in the Otoroshi LLM Extension (it should be enabled by default)",source:"@site/docs/cost-optimizations/costs-tracking.mdx",sourceDirName:"cost-optimizations",slug:"/cost-optimizations/costs-tracking",permalink:"/otoroshi-llm-extension/docs/cost-optimizations/costs-tracking",draft:!1,unlisted:!1,tags:[],version:"current",sidebarPosition:2,frontMatter:{sidebar_position:2},sidebar:"tutorialSidebar",previous:{title:"Managing tokens usage",permalink:"/otoroshi-llm-extension/docs/cost-optimizations/quotas"},next:{title:"Simple cache",permalink:"/otoroshi-llm-extension/docs/cost-optimizations/simple-cache"}},l={},c=[{value:"Example of costs tracking embed in responses",id:"example-of-costs-tracking-embed-in-responses",level:2},{value:"Example of LLMUsageAudit event with costs tracking",id:"example-of-llmusageaudit-event-with-costs-tracking",level:2}];function d(n){const e={a:"a",code:"code",h1:"h1",h2:"h2",li:"li",p:"p",pre:"pre",ul:"ul",...(0,s.R)(),...n.components};return(0,o.jsxs)(o.Fragment,{children:[(0,o.jsx)(e.h1,{id:"-costs-tracking",children:"\ud83d\udcb2 Costs tracking"}),"\n",(0,o.jsx)(e.p,{children:"If you want to track the costs of your LLM Usage, you can enable it in the Otoroshi LLM Extension (it should be enabled by default)"}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-conf",children:"costs-tracking {\n  enabled = true\n  enabled = ${?CLOUD_APIM_EXTENSIONS_LLM_EXTENSION_COSTS_TRACKING_ENABLED}\n  embed-costs-tracking-in-responses = false\n  embed-costs-tracking-in-responses = ${?CLOUD_APIM_EXTENSIONS_LLM_EXTENSION_COSTS_TRACKING_EMBED_COSTS_TRACKING_IN_RESPONSES}\n}\n"})}),"\n",(0,o.jsxs)(e.p,{children:["Once it's enabled, audit events of kind ",(0,o.jsx)(e.code,{children:"LLMUsageAudit"})," will have an ",(0,o.jsx)(e.code,{children:"costs"}),".\nYou can also embed the ",(0,o.jsx)(e.code,{children:"costs"})," value in your LLM responses using the ",(0,o.jsx)(e.code,{children:"impacts.embed-impacts-in-responses"})," config."]}),"\n",(0,o.jsxs)(e.p,{children:["The costs tracking  computation is based on project ",(0,o.jsx)(e.a,{href:"https://docs.litellm.ai/",children:"LitLLM"})," models price dictionnary and only supports right now the following providers"]}),"\n",(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsx)(e.li,{children:"openai"}),"\n",(0,o.jsx)(e.li,{children:"deepseek"}),"\n",(0,o.jsx)(e.li,{children:"x-ai"}),"\n",(0,o.jsx)(e.li,{children:"azure-openai"}),"\n",(0,o.jsx)(e.li,{children:"cloudflare"}),"\n",(0,o.jsx)(e.li,{children:"gemini"}),"\n",(0,o.jsx)(e.li,{children:"mistral"}),"\n",(0,o.jsx)(e.li,{children:"ollama"}),"\n",(0,o.jsx)(e.li,{children:"cohere"}),"\n",(0,o.jsx)(e.li,{children:"anthropic"}),"\n",(0,o.jsx)(e.li,{children:"groq"}),"\n"]}),"\n",(0,o.jsx)(e.p,{children:"but if you're okay with approximations, you can set some metadata on your providers to use supported providers / models"}),"\n",(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.code,{children:"costs-tracking-provider"}),": the provider used for costs tracking computation"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.code,{children:"eco-impacts-model"}),": the model used for eco costs tracking computation"]}),"\n"]}),"\n",(0,o.jsx)(e.h2,{id:"example-of-costs-tracking-embed-in-responses",children:"Example of costs tracking embed in responses"}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-sh",children:'$ curl --request POST \\\n  --url \'http://ecologits.oto.tools:9999/v1/chat/completions?embed_=true&embed_costs=true\' \\\n  --header \'authorization: Bearer otoapk_mqXJ9YrgVM0rcGZy_0a35ab6e5b5407cc7200f94f43f60c583928d372ef43b99a28b93243c3c90153\' \\\n  --header \'content-type: application/json\' \\\n  --data \'{\n  "messages": [\n    {\n      "role": "user",\n      "content": "tell me a joke"\n    }\n  ]\n}\'\n\n{\n  "id": "chatcmpl-VRyJP4WKPFG2bWODCKp0yXn3UkwtpdnQ",\n  "object": "chat.completion",\n  "created": 1743169375,\n  "model": "gpt-4o-mini",\n  "system_fingerprint": "fp-CGPX1MTbpRo7OvGCR0MPPwZiXz9sm8N0",\n  "choices": [\n    {\n      "index": 0,\n      "message": {\n        "role": "assistant",\n        "content": "Why did the scarecrow win an award?\\n\\nBecause he was outstanding in his field!"\n      },\n      "logprobs": null,\n      "finish_reason": "stop"\n    }\n  ],\n  "usage": {\n    "prompt_tokens": 11,\n    "completion_tokens": 18,\n    "total_tokens": 29,\n    "completion_tokens_details": {\n      "reasoning_tokens": 0\n    }\n  },\n  "costs": {\n    "input_cost": 0.00000165,\n    "output_cost": 0.0000108,\n    "reasoning_cost": 0,\n    "total_cost": 0.00001245,\n    "currency": "dollar"\n  }\n}\n'})}),"\n",(0,o.jsx)(e.h2,{id:"example-of-llmusageaudit-event-with-costs-tracking",children:"Example of LLMUsageAudit event with costs tracking"}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-json",children:'{\n  "@id" : "1905616593920983819",\n  "@timestamp" : 1743169375292,\n  "@type" : "AuditEvent",\n  "@product" : "otoroshi",\n  "@serviceId" : "",\n  "@service" : "Otoroshi",\n  "@env" : "dev",\n  "audit" : "LLMUsageAudit",\n  "provider_kind" : "openai",\n  "provider" : "provider_10bbc76d-7cd8-4cb7-b760-61e749a1b691",\n  "duration" : 415,\n  "model" : "gpt-4o-mini",\n  "rate_limit" : {\n    "requests_limit" : 10000,\n    "requests_remaining" : 9999,\n    "tokens_limit" : 200000,\n    "tokens_remaining" : 199993\n  },\n  "usage" : {\n    "prompt_tokens" : 11,\n    "generation_tokens" : 18,\n    "reasoning_tokens" : 0\n  },\n  "error" : null,\n  "consumed_using" : "chat/completion/blocking",\n  "user" : null,\n  "apikey" : null,\n  "route" : {\n    "_loc" : {\n      "tenant" : "default",\n      "teams" : [ "default" ]\n    },\n    "id" : "route_e4a9d6cb3-d859-4203-a860-8d1dd6d09557",\n    "name" : "ecologits",\n    "description" : "A new route",\n    "tags" : [ ],\n    "metadata" : {\n      "created_at" : "2025-03-28T10:10:19.448+01:00",\n      "updated_at" : "2025-03-28T10:48:48.218+01:00"\n    },\n    "enabled" : true,\n    "debug_flow" : false,\n    "export_reporting" : false,\n    "capture" : false,\n    "groups" : [ "default" ],\n    "bound_listeners" : [ ],\n    "frontend" : {\n      "domains" : [ "test.oto.tools" ],\n      "strip_path" : true,\n      "exact" : false,\n      "headers" : { },\n      "query" : { },\n      "methods" : [ ]\n    },\n    "backend" : {\n      "targets" : [ {\n        "id" : "target_1",\n        "hostname" : "request.otoroshi.io",\n        "port" : 443,\n        "tls" : true,\n        "weight" : 1,\n        "backup" : false,\n        "predicate" : {\n          "type" : "AlwaysMatch"\n        },\n        "protocol" : "HTTP/1.1",\n        "ip_address" : null,\n        "tls_config" : {\n          "certs" : [ ],\n          "trusted_certs" : [ ],\n          "enabled" : false,\n          "loose" : false,\n          "trust_all" : false\n        }\n      } ],\n      "root" : "/",\n      "rewrite" : false,\n      "load_balancing" : {\n        "type" : "RoundRobin"\n      },\n      "client" : {\n        "retries" : 1,\n        "max_errors" : 20,\n        "retry_initial_delay" : 50,\n        "backoff_factor" : 2,\n        "call_timeout" : 30000,\n        "call_and_stream_timeout" : 120000,\n        "connection_timeout" : 10000,\n        "idle_timeout" : 60000,\n        "global_timeout" : 30000,\n        "sample_interval" : 2000,\n        "proxy" : { },\n        "custom_timeouts" : [ ],\n        "cache_connection_settings" : {\n          "enabled" : false,\n          "queue_size" : 2048\n        }\n      },\n      "health_check" : {\n        "enabled" : false,\n        "url" : "",\n        "timeout" : 5000,\n        "healthyStatuses" : [ ],\n        "unhealthyStatuses" : [ ]\n      }\n    },\n    "backend_ref" : null,\n    "plugins" : [ {\n      "enabled" : true,\n      "debug" : false,\n      "plugin" : "cp:otoroshi.next.plugins.OverrideHost",\n      "include" : [ ],\n      "exclude" : [ ],\n      "config" : { },\n      "bound_listeners" : [ ],\n      "plugin_index" : {\n        "transform_request" : 0\n      }\n    }, {\n      "enabled" : true,\n      "debug" : false,\n      "plugin" : "cp:otoroshi_plugins.com.cloud.apim.otoroshi.extensions.aigateway.plugins.OpenAiCompatProxy",\n      "include" : [ ],\n      "exclude" : [ ],\n      "config" : {\n        "refs" : [ "provider_10bbc76d-7cd8-4cb7-b760-61e749a1b691" ]\n      },\n      "bound_listeners" : [ ],\n      "plugin_index" : { }\n    } ]\n  },\n  "input_prompt" : [ {\n    "role" : "user",\n    "content" : "tell me a joke"\n  } ],\n  "output" : {\n    "generations" : [ {\n      "message" : {\n        "role" : "assistant",\n        "content" : "Why did the scarecrow win an award?\\n\\nBecause he was outstanding in his field!"\n      }\n    } ],\n    "metadata" : {\n      "rate_limit" : {\n        "requests_limit" : 10000,\n        "requests_remaining" : 9999,\n        "tokens_limit" : 200000,\n        "tokens_remaining" : 199993\n      },\n      "usage" : {\n        "prompt_tokens" : 11,\n        "generation_tokens" : 18,\n        "reasoning_tokens" : 0\n      },\n      "costs" : {\n        "input_cost" : 0.00000165,\n        "output_cost" : 0.0000108,\n        "reasoning_cost" : 0,\n        "total_cost" : 0.00001245,\n        "currency" : "dollar"\n      }\n    }\n  },\n  "provider_details" : {\n    "_loc" : {\n      "tenant" : "default",\n      "teams" : [ "default" ]\n    },\n    "id" : "provider_10bbc76d-7cd8-4cb7-b760-61e749a1b691",\n    "name" : "OpenAI clean",\n    "description" : "An OpenAI LLM api provider",\n    "metadata" : {\n      "created_at" : "2025-03-28T10:10:51.558+01:00"\n    },\n    "tags" : [ ],\n    "provider" : "openai",\n    "connection" : {\n      "base_url" : "https://api.openai.com/v1",\n      "token" : "xxx",\n      "timeout" : 30000\n    },\n    "options" : {\n      "model" : "gpt-4o-mini",\n      "frequency_penalty" : null,\n      "logit_bias" : null,\n      "logprobs" : null,\n      "top_logprobs" : null,\n      "max_tokens" : null,\n      "n" : 1,\n      "presence_penalty" : null,\n      "response_format" : null,\n      "seed" : null,\n      "stop" : null,\n      "stream" : false,\n      "temperature" : 1,\n      "top_p" : 1,\n      "tools" : null,\n      "tool_choice" : null,\n      "user" : null,\n      "wasm_tools" : [ ],\n      "mcp_connectors" : [ ],\n      "allow_config_override" : true\n    },\n    "provider_fallback" : null,\n    "context" : {\n      "default" : null,\n      "contexts" : [ ]\n    },\n    "models" : {\n      "include" : [ ],\n      "exclude" : [ ]\n    },\n    "guardrails" : [ ],\n    "guardrails_fail_on_deny" : false,\n    "cache" : {\n      "strategy" : "none",\n      "ttl" : 300000,\n      "score" : 0.8\n    }\n  },\n  "costs": {\n    "input_cost": 0.00000165,\n    "output_cost": 0.0000108,\n    "reasoning_cost": 0,\n    "total_cost": 0.00001245,\n    "currency": "dollar"\n  }\n}\n'})})]})}function u(n={}){const{wrapper:e}={...(0,s.R)(),...n.components};return e?(0,o.jsx)(e,{...n,children:(0,o.jsx)(d,{...n})}):d(n)}},9229:(n,e,t)=>{t(6540),t(4848)},8453:(n,e,t)=>{t.d(e,{R:()=>a,x:()=>r});var o=t(6540);const s={},i=o.createContext(s);function a(n){const e=o.useContext(i);return o.useMemo((function(){return"function"==typeof n?n(e):{...e,...n}}),[e,n])}function r(n){let e;return e=n.disableParentContext?"function"==typeof n.components?n.components(s):n.components||s:a(n.components),o.createElement(i.Provider,{value:e},n.children)}}}]);
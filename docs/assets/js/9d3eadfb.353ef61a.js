"use strict";(self.webpackChunkdocumentation=self.webpackChunkdocumentation||[]).push([[79],{6816:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>p,contentTitle:()=>s,default:()=>m,frontMatter:()=>o,metadata:()=>c,toc:()=>a});var i=t(4848),r=t(8453);t(9229);const o={sidebar_position:2},s="Overview",c={id:"prompt-engineering/overview",title:"Overview",description:"Prompt engineering enhances interactions with LLMs by optimizing prompt structure, leveraging contextual information, and utilizing templating techniques.",source:"@site/docs/prompt-engineering/overview.mdx",sourceDirName:"prompt-engineering",slug:"/prompt-engineering/overview",permalink:"/otoroshi-llm-extension/docs/prompt-engineering/overview",draft:!1,unlisted:!1,tags:[],version:"current",sidebarPosition:2,frontMatter:{sidebar_position:2},sidebar:"tutorialSidebar",previous:{title:"Prompt Engineering",permalink:"/otoroshi-llm-extension/docs/category/prompt-engineering"},next:{title:"Prompt templating",permalink:"/otoroshi-llm-extension/docs/prompt-engineering/prompt-templating"}},p={},a=[{value:"Prompt Templating",id:"prompt-templating",level:2},{value:"Context Injection",id:"context-injection",level:2},{value:"Demo",id:"demo",level:2}];function l(e){const n={h1:"h1",h2:"h2",p:"p",...(0,r.R)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(n.h1,{id:"overview",children:"Overview"}),"\n",(0,i.jsx)(n.p,{children:"Prompt engineering enhances interactions with LLMs by optimizing prompt structure, leveraging contextual information, and utilizing templating techniques."}),"\n",(0,i.jsx)(n.p,{children:"This ensures efficient, accurate, and cost-effective responses for your users."}),"\n",(0,i.jsx)(n.h2,{id:"prompt-templating",children:"Prompt Templating"}),"\n",(0,i.jsx)(n.p,{children:"Prompt templating allows users to define standardized templates for commonly used queries, reducing redundancy and improving response consistency."}),"\n",(0,i.jsx)(n.h2,{id:"context-injection",children:"Context Injection"}),"\n",(0,i.jsx)(n.p,{children:"Context injection improves LLM responses by supplying relevant background information, enabling more precise and insightful answers."}),"\n",(0,i.jsx)(n.h2,{id:"demo",children:"Demo"}),"\n",(0,i.jsx)("iframe",{width:"956",height:"538",src:"https://www.youtube.com/embed/SqyKki3We90?si=by-ITIPZb1lLTgPW",title:"YouTube video player",frameborder:"0",allow:"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share",referrerpolicy:"strict-origin-when-cross-origin",allowfullscreen:!0})]})}function m(e={}){const{wrapper:n}={...(0,r.R)(),...e.components};return n?(0,i.jsx)(n,{...e,children:(0,i.jsx)(l,{...e})}):l(e)}},9229:(e,n,t)=>{t(6540),t(4848)},8453:(e,n,t)=>{t.d(n,{R:()=>s,x:()=>c});var i=t(6540);const r={},o=i.createContext(r);function s(e){const n=i.useContext(o);return i.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function c(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:s(e.components),i.createElement(o.Provider,{value:n},e.children)}}}]);
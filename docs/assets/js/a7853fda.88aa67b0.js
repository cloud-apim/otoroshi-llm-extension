"use strict";(self.webpackChunkdocumentation=self.webpackChunkdocumentation||[]).push([[9832],{3398:(e,r,n)=>{n.r(r),n.d(r,{assets:()=>d,contentTitle:()=>s,default:()=>u,frontMatter:()=>a,metadata:()=>o,toc:()=>l});var t=n(4848),i=n(8453);n(9229);const a={},s="Prompt contains gender bias guardrail",o={id:"guardrails/gender_bias",title:"Prompt contains gender bias guardrail",description:"A mechanism that identifies and reduces biased language related to gender in user prompts, promoting fairness and inclusivity in AI-generated content. It can be applied before the LLM receives the request (blocking biased prompts) and after to filter or rephrase biased responses.",source:"@site/docs/guardrails/gender_bias.mdx",sourceDirName:"guardrails",slug:"/guardrails/gender_bias",permalink:"/otoroshi-llm-extension/docs/guardrails/gender_bias",draft:!1,unlisted:!1,tags:[],version:"current",frontMatter:{},sidebar:"tutorialSidebar",previous:{title:"Prompt contains guardrail",permalink:"/otoroshi-llm-extension/docs/guardrails/contains"},next:{title:"Prompt contains gibberish guardrail",permalink:"/otoroshi-llm-extension/docs/guardrails/gibberish"}},d={},l=[{value:"Guardrail example",id:"guardrail-example",level:3}];function c(e){const r={h1:"h1",h3:"h3",img:"img",p:"p",...(0,i.R)(),...e.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(r.h1,{id:"prompt-contains-gender-bias-guardrail",children:"Prompt contains gender bias guardrail"}),"\n",(0,t.jsx)(r.p,{children:(0,t.jsx)(r.img,{src:n(8645).A+"",width:"1634",height:"464"})}),"\n",(0,t.jsx)(r.p,{children:"A mechanism that identifies and reduces biased language related to gender in user prompts, promoting fairness and inclusivity in AI-generated content. It can be applied before the LLM receives the request (blocking biased prompts) and after to filter or rephrase biased responses."}),"\n",(0,t.jsx)(r.h3,{id:"guardrail-example",children:"Guardrail example"}),"\n",(0,t.jsx)(r.p,{children:'If a user asks, "Why are women bad at driving ?", the LLM will either block the request or reframe it in a neutral way before processing it.'}),"\n",(0,t.jsx)(r.p,{children:"If a response contains gender bias, it will be adjusted before being displayed."})]})}function u(e={}){const{wrapper:r}={...(0,i.R)(),...e.components};return r?(0,t.jsx)(r,{...e,children:(0,t.jsx)(c,{...e})}):c(e)}},9229:(e,r,n)=>{n(6540),n(4848)},8645:(e,r,n)=>{n.d(r,{A:()=>t});const t=n.p+"assets/images/guardrails-gender-bias-80433e54cd7db422719639ea44916c28.png"},8453:(e,r,n)=>{n.d(r,{R:()=>s,x:()=>o});var t=n(6540);const i={},a=t.createContext(i);function s(e){const r=t.useContext(a);return t.useMemo((function(){return"function"==typeof e?e(r):{...r,...e}}),[r,e])}function o(e){let r;return r=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:s(e.components),t.createElement(a.Provider,{value:r},e.children)}}}]);
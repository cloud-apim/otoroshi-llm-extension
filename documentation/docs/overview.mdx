---
sidebar_position: 1
---

import Terminal from '@site/src/components/Terminal';

# Overview

**Connect, setup, secure and seamlessly manage LLM models using an Universal/OpenAI compatible API**

  - **Unified interface**: Simplify interactions and minimize integration hassles
  - **Use multiple providers**: 10+ LLM providers supported right now, a lot more coming
  - **Load balancing**: Ensure optimal performance by distributing workloads across multiple providers
  - **Fallbacks**: Automatically switch LLMs during failures to deliver uninterrupted & accurate performance
  - **Automatic retries**: LLM APIs often have inexplicable failures. You can rescue a substantial number of your requests with our in-built automatic retries feature.
  - **Semantic cache**: Speed up repeated queries, enhance response times, and reduce costs
  - **Custom quotas**: Manage LLM tokens quotas per consumer and optimise costs
  - **Key vault**: securely store your LLM API keys in Otoroshi vault or any other secret vault supported by Otoroshi.
  - **Observability and reporting**: every LLM request is audited with details about the consumer, the LLM provider and usage. All those audit events are exportable using multiple methods for further reporting
  - **Fine grained authorizations**: Use Otoroshi advanced fine grained authorizations capabilities to constrains model usage based on whatever you want: user identity, apikey, consumer metadata, request details, etc
  - **Prompt Fences**: Validate your prompts and prompts responses to avoid sensitive or personal informations leakage, irrelevant or unhelpful responses, gibberish content, etc
  - **Prompt engineering**: enhance your experience by providing contextual information to your prompts, storing them in a library for reusability, and using prompt templates for increased efficiency

Otoroshi LLM Extension is set of Otoroshi plugins and resources to interact with LLMs, let's discover it

## Supported LLM providers

All supported models are listed [here](/docs/providers)

* Anthropic 
* Azure OpenAI
* Cloudflare
* Cohere
* Gemini
* Groq
* Huggingface ðŸ‡«ðŸ‡· ðŸ‡ªðŸ‡º
* Mistral ðŸ‡«ðŸ‡· ðŸ‡ªðŸ‡º
* Ollama (Local Models)
* OpenAI
* OVH AI Endpoints ðŸ‡«ðŸ‡· ðŸ‡ªðŸ‡º
* Scaleway ðŸ‡«ðŸ‡· ðŸ‡ªðŸ‡º
* X.ai
* Deepseek

## Introduction video

<iframe width="956" height="538" src="https://www.youtube.com/embed/M8sA9xuE3gs?si=nSB80iS1Et9Q3eIT" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>

---
sidebar_position: 5
---

import Terminal from '@site/src/components/Terminal';

# Resilience

## Provider fallback

![fallback](../static/img/fallback.png)

## Provider loadbalancing

![lb](../static/img/lb.png)


Resilience ensures that LLM interactions remain highly available and fault-tolerant, even when providers experience outages or failures.

Key Features

Load Balancing: Distribute requests across multiple providers to optimize performance.

Fallback Mechanism: Automatically switch to alternative LLMs in case of failures.

Automatic Retries: Retry failed requests based on configurable rules to maximize successful responses.

Rate Limiting & Quotas: Prevent overloading a single provider by distributing usage effectively.

How It Works

Requests are first sent to a primary LLM provider.

If the request fails, the system retries or falls back to a secondary provider.

Load balancing ensures even distribution, reducing provider overload.

The semantic cache minimizes redundant API calls by reusing past responses.
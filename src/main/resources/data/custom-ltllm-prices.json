{
  "sample_spec": {
    "max_tokens": "LEGACY parameter. set to max_output_tokens if provider specifies it. IF not set to max_input_tokens, if provider specifies it.",
    "max_input_tokens": "max input tokens, if the provider specifies it. if not default to max_tokens",
    "max_output_tokens": "max output tokens, if the provider specifies it. if not default to max_tokens",
    "input_cost_per_token": 0.0000,
    "output_cost_per_token": 0.000,
    "output_cost_per_reasoning_token": 0.000,
    "litellm_provider": "one of https://docs.litellm.ai/docs/providers",
    "mode": "one of: chat, embedding, completion, image_generation, audio_transcription, audio_speech, image_generation, moderation, rerank",
    "supports_function_calling": true,
    "supports_parallel_function_calling": true,
    "supports_vision": true,
    "supports_audio_input": true,
    "supports_audio_output": true,
    "supports_prompt_caching": true,
    "supports_response_schema": true,
    "supports_system_messages": true,
    "supports_reasoning": true,
    "supports_web_search": true,
    "search_context_cost_per_query": {
      "search_context_size_low": 0.0000,
      "search_context_size_medium": 0.0000,
      "search_context_size_high": 0.0000
    },
    "deprecation_date": "date when the model becomes deprecated in the format YYYY-MM-DD"
  }
}